

<!DOCTYPE html>
<html lang="zh-CN" data-default-color-scheme=auto>



<head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="/img/R-C.png">
  <link rel="icon" href="/img/R-C.png">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="author" content="PixelPilot">
  <meta name="keywords" content="">
  
    <meta name="description" content="Image Super-Resolution Using Very Deep Residual Channel Attention Networks 精读笔记 背景 这是一篇收录在ECCV2018的一篇单幅图像超分辨率论文 论文链接：Image Super-Resolution Using Very Deep Residual Channel Attention Networks">
<meta property="og:type" content="article">
<meta property="og:title" content="Image Super-Resolution Using Very Deep Residual Channel Attention Networks 精读笔记">
<meta property="og:url" content="https://pixelpilot666.github.io/2023/06/09/Image-Super-Resolution-Using-Very-Deep-Residual-Channel-Attention-Networks-%E7%B2%BE%E8%AF%BB%E7%AC%94%E8%AE%B0/index.html">
<meta property="og:site_name" content="Pixel Space">
<meta property="og:description" content="Image Super-Resolution Using Very Deep Residual Channel Attention Networks 精读笔记 背景 这是一篇收录在ECCV2018的一篇单幅图像超分辨率论文 论文链接：Image Super-Resolution Using Very Deep Residual Channel Attention Networks">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://pixelpilot666.github.io/2023/06/09/Image-Super-Resolution-Using-Very-Deep-Residual-Channel-Attention-Networks-%E7%B2%BE%E8%AF%BB%E7%AC%94%E8%AE%B0/image-RCAN.png">
<meta property="og:image" content="https://pixelpilot666.github.io/2023/06/09/Image-Super-Resolution-Using-Very-Deep-Residual-Channel-Attention-Networks-%E7%B2%BE%E8%AF%BB%E7%AC%94%E8%AE%B0/image-20230609173912082.png">
<meta property="og:image" content="https://pixelpilot666.github.io/2023/06/09/Image-Super-Resolution-Using-Very-Deep-Residual-Channel-Attention-Networks-%E7%B2%BE%E8%AF%BB%E7%AC%94%E8%AE%B0/image-20230609174314668.png">
<meta property="og:image" content="https://pixelpilot666.github.io/2023/06/09/Image-Super-Resolution-Using-Very-Deep-Residual-Channel-Attention-Networks-%E7%B2%BE%E8%AF%BB%E7%AC%94%E8%AE%B0/image-20230609175456667.png">
<meta property="og:image" content="https://pixelpilot666.github.io/2023/06/09/Image-Super-Resolution-Using-Very-Deep-Residual-Channel-Attention-Networks-%E7%B2%BE%E8%AF%BB%E7%AC%94%E8%AE%B0/image-20230609180502114.png">
<meta property="og:image" content="https://pixelpilot666.github.io/2023/06/09/Image-Super-Resolution-Using-Very-Deep-Residual-Channel-Attention-Networks-%E7%B2%BE%E8%AF%BB%E7%AC%94%E8%AE%B0/image-20230609180843475.png">
<meta property="og:image" content="https://pixelpilot666.github.io/2023/06/09/Image-Super-Resolution-Using-Very-Deep-Residual-Channel-Attention-Networks-%E7%B2%BE%E8%AF%BB%E7%AC%94%E8%AE%B0/image-20230609181422088.png">
<meta property="og:image" content="https://pixelpilot666.github.io/2023/06/09/Image-Super-Resolution-Using-Very-Deep-Residual-Channel-Attention-Networks-%E7%B2%BE%E8%AF%BB%E7%AC%94%E8%AE%B0/image-20230611152739652.png">
<meta property="og:image" content="https://pixelpilot666.github.io/2023/06/09/Image-Super-Resolution-Using-Very-Deep-Residual-Channel-Attention-Networks-%E7%B2%BE%E8%AF%BB%E7%AC%94%E8%AE%B0/image-20230611152832760.png">
<meta property="og:image" content="https://pixelpilot666.github.io/2023/06/09/Image-Super-Resolution-Using-Very-Deep-Residual-Channel-Attention-Networks-%E7%B2%BE%E8%AF%BB%E7%AC%94%E8%AE%B0/image-20230611152915204.png">
<meta property="og:image" content="https://pixelpilot666.github.io/2023/06/09/Image-Super-Resolution-Using-Very-Deep-Residual-Channel-Attention-Networks-%E7%B2%BE%E8%AF%BB%E7%AC%94%E8%AE%B0/image-20230611153000026.png">
<meta property="og:image" content="https://pixelpilot666.github.io/2023/06/09/Image-Super-Resolution-Using-Very-Deep-Residual-Channel-Attention-Networks-%E7%B2%BE%E8%AF%BB%E7%AC%94%E8%AE%B0/image-20230611153017387.png">
<meta property="og:image" content="https://pixelpilot666.github.io/2023/06/09/Image-Super-Resolution-Using-Very-Deep-Residual-Channel-Attention-Networks-%E7%B2%BE%E8%AF%BB%E7%AC%94%E8%AE%B0/image-20230611153348034.png">
<meta property="og:image" content="https://pixelpilot666.github.io/2023/06/09/Image-Super-Resolution-Using-Very-Deep-Residual-Channel-Attention-Networks-%E7%B2%BE%E8%AF%BB%E7%AC%94%E8%AE%B0/image-20230611153554031.png">
<meta property="og:image" content="https://pixelpilot666.github.io/2023/06/09/Image-Super-Resolution-Using-Very-Deep-Residual-Channel-Attention-Networks-%E7%B2%BE%E8%AF%BB%E7%AC%94%E8%AE%B0/image-20230611153627432.png">
<meta property="og:image" content="https://pixelpilot666.github.io/2023/06/09/Image-Super-Resolution-Using-Very-Deep-Residual-Channel-Attention-Networks-%E7%B2%BE%E8%AF%BB%E7%AC%94%E8%AE%B0/image-20230611153654173.png">
<meta property="og:image" content="https://pixelpilot666.github.io/2023/06/09/Image-Super-Resolution-Using-Very-Deep-Residual-Channel-Attention-Networks-%E7%B2%BE%E8%AF%BB%E7%AC%94%E8%AE%B0/image-20230611153658316.png">
<meta property="og:image" content="https://pixelpilot666.github.io/2023/06/09/Image-Super-Resolution-Using-Very-Deep-Residual-Channel-Attention-Networks-%E7%B2%BE%E8%AF%BB%E7%AC%94%E8%AE%B0/image-20230611153702383.png">
<meta property="og:image" content="https://pixelpilot666.github.io/2023/06/09/Image-Super-Resolution-Using-Very-Deep-Residual-Channel-Attention-Networks-%E7%B2%BE%E8%AF%BB%E7%AC%94%E8%AE%B0/image-20230611153706621.png">
<meta property="og:image" content="https://pixelpilot666.github.io/2023/06/09/Image-Super-Resolution-Using-Very-Deep-Residual-Channel-Attention-Networks-%E7%B2%BE%E8%AF%BB%E7%AC%94%E8%AE%B0/image-20230611153712884.png">
<meta property="og:image" content="https://pixelpilot666.github.io/2023/06/09/Image-Super-Resolution-Using-Very-Deep-Residual-Channel-Attention-Networks-%E7%B2%BE%E8%AF%BB%E7%AC%94%E8%AE%B0/image-20230611153720505.png">
<meta property="og:image" content="https://pixelpilot666.github.io/2023/06/09/Image-Super-Resolution-Using-Very-Deep-Residual-Channel-Attention-Networks-%E7%B2%BE%E8%AF%BB%E7%AC%94%E8%AE%B0/image-20230611153724001.png">
<meta property="og:image" content="https://pixelpilot666.github.io/2023/06/09/Image-Super-Resolution-Using-Very-Deep-Residual-Channel-Attention-Networks-%E7%B2%BE%E8%AF%BB%E7%AC%94%E8%AE%B0/image-20230611153727546.png">
<meta property="og:image" content="https://pixelpilot666.github.io/2023/06/09/Image-Super-Resolution-Using-Very-Deep-Residual-Channel-Attention-Networks-%E7%B2%BE%E8%AF%BB%E7%AC%94%E8%AE%B0/image-20230611153731936.png">
<meta property="og:image" content="https://pixelpilot666.github.io/2023/06/09/Image-Super-Resolution-Using-Very-Deep-Residual-Channel-Attention-Networks-%E7%B2%BE%E8%AF%BB%E7%AC%94%E8%AE%B0/image-20230611153734640.png">
<meta property="og:image" content="https://pixelpilot666.github.io/2023/06/09/Image-Super-Resolution-Using-Very-Deep-Residual-Channel-Attention-Networks-%E7%B2%BE%E8%AF%BB%E7%AC%94%E8%AE%B0/image-20230611153738113.png">
<meta property="article:published_time" content="2023-06-09T09:09:11.000Z">
<meta property="article:modified_time" content="2024-03-03T08:25:20.949Z">
<meta property="article:author" content="PixelPilot">
<meta property="article:tag" content="RCAN单幅图像超分辨率">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="https://pixelpilot666.github.io/2023/06/09/Image-Super-Resolution-Using-Very-Deep-Residual-Channel-Attention-Networks-%E7%B2%BE%E8%AF%BB%E7%AC%94%E8%AE%B0/image-RCAN.png">
  
  
    <meta name="referrer" content="no-referrer-when-downgrade">
  
  
  <title>Image Super-Resolution Using Very Deep Residual Channel Attention Networks 精读笔记 - Pixel Space</title>

  <link  rel="stylesheet" href="https://lib.baomitu.com/twitter-bootstrap/4.6.1/css/bootstrap.min.css" />



  <link  rel="stylesheet" href="https://lib.baomitu.com/github-markdown-css/4.0.0/github-markdown.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css" />



<!-- 主题依赖的图标库，不要自行修改 -->
<!-- Do not modify the link that theme dependent icons -->

<link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_hj8rtnfg7um.css">



<link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_lbnruvf0jn.css">


<link  rel="stylesheet" href="/css/main.css" />


  <link id="highlight-css" rel="stylesheet" href="/css/highlight.css" />
  
    <link id="highlight-css-dark" rel="stylesheet" href="/css/highlight-dark.css" />
  




  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    Fluid.ctx = Object.assign({}, Fluid.ctx)
    var CONFIG = {"hostname":"pixelpilot666.github.io","root":"/","version":"1.9.4","typing":{"enable":true,"typeSpeed":70,"cursorChar":"_","loop":false,"scope":[]},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"left","visible":"hover","icon":""},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"code_language":{"enable":true,"default":"TEXT"},"copy_btn":true,"image_caption":{"enable":true},"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"placement":"right","headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":0},"lazyload":{"enable":true,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":true,"follow_dnt":true,"baidu":null,"google":null,"gtag":null,"tencent":{"sid":null,"cid":null},"woyaola":null,"cnzz":null,"leancloud":{"app_id":"2yoCLZjZLSAUgnMqvJ5vzl0I-gzGzoHsz","app_key":"TAADaGFWou9xASz6lIeA4JGy","server_url":"https://2yoclzjz.lc-cn-n1-shared.com","path":"window.location.pathname","ignore_local":false}},"search_path":"/local-search.xml"};

    if (CONFIG.web_analytics.follow_dnt) {
      var dntVal = navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack;
      Fluid.ctx.dnt = dntVal && (dntVal.startsWith('1') || dntVal.startsWith('yes') || dntVal.startsWith('on'));
    }
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>
  

  

  

  

  

  

  

  
    
  



  
<meta name="generator" content="Hexo 6.3.0"></head>


<body>
  

  <header>
    

<div class="header-inner" style="height: 70vh;">
  <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand" href="/">
      <strong>Pixel Space</strong>
    </a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/">
                <i class="iconfont icon-home-fill"></i>
                <span>首页</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/">
                <i class="iconfont icon-archive-fill"></i>
                <span>归档</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/">
                <i class="iconfont icon-category-fill"></i>
                <span>分类</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/">
                <i class="iconfont icon-tags-fill"></i>
                <span>标签</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/">
                <i class="iconfont icon-user-fill"></i>
                <span>关于</span>
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">
              <i class="iconfont icon-search"></i>
            </a>
          </li>
          
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle">
              <i class="iconfont icon-dark" id="color-toggle-icon"></i>
            </a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

  

<div id="banner" class="banner" parallax=true
     style="background: url('/img/girl.jpg') no-repeat center center; background-size: cover;">
  <div class="full-bg-img">
    <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
      <div class="banner-text text-center fade-in-up">
        <div class="h2">
          
            <span id="subtitle" data-typed-text="Image Super-Resolution Using Very Deep Residual Channel Attention Networks 精读笔记"></span>
          
        </div>

        
          
  <div class="mt-3">
    
    
      <span class="post-meta">
        <i class="iconfont icon-date-fill" aria-hidden="true"></i>
        <time datetime="2023-06-09 17:09" pubdate>
          2023年6月9日 下午
        </time>
      </span>
    
  </div>

  <div class="mt-1">
    
      <span class="post-meta mr-2">
        <i class="iconfont icon-chart"></i>
        
          5.1k 字
        
      </span>
    

    
      <span class="post-meta mr-2">
        <i class="iconfont icon-clock-fill"></i>
        
        
        
          43 分钟
        
      </span>
    

    
    
      
        <span id="busuanzi_container_page_pv" style="display: none">
          <i class="iconfont icon-eye" aria-hidden="true"></i>
          <span id="busuanzi_value_page_pv"></span> 次
        </span>
        
      
    
  </div>


        
      </div>

      
    </div>
  </div>
</div>

</div>

  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="side-col d-none d-lg-block col-lg-2">
      

    </div>

    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div id="board">
          <article class="post-content mx-auto">
            <!-- SEO header -->
            <h1 style="display: none">Image Super-Resolution Using Very Deep Residual Channel Attention Networks 精读笔记</h1>
            
            
              <div class="markdown-body">
                
                <h1
id="image-super-resolution-using-very-deep-residual-channel-attention-networks-精读笔记">Image
Super-Resolution Using Very Deep Residual Channel Attention Networks
精读笔记</h1>
<h2 id="背景">背景</h2>
<p>这是一篇收录在ECCV2018的一篇单幅图像超分辨率论文</p>
<p>论文链接：<a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1807.02758.pdf">Image
Super-Resolution Using Very Deep Residual Channel Attention
Networks</a></p>
<p>这篇论文主要解决两个问题：</p>
<ol type="1">
<li>CNN网络的深度对SR效果的提升有很大的影响，但是因为梯度消失、梯度爆炸、深度网络退化，所以用作SR的更深的卷积神经网络更难被训练。</li>
<li>低分辨率的输入和特征都包含了很多应该被舍弃的低频信息，但是这些低频信息却跟高频信息一样的重要程度去参与训练，这样就降低了CNN的表征能力。</li>
</ol>
<h2 id="解决措施">解决措施</h2>
<ol type="1">
<li>为了解决更深的CNN难以训练，作者在网络中引入残差块，使得网络的深度大大增加。但是仅仅简单的叠加残差块，难以实现好的效果，所以作者提出了残差嵌套（RIR）结构，结构中的长跳链接（LSC）、短跳链接（SSC）以及残差块内的跨层链接都有助于绕过低频信息，让网络学习到更多的高频信息。</li>
<li>为了解决包含了更多高频信息的通道和包含了更多低频信息的通道以同样的重要程度参与训练的问题，作者引入了通道注意力机制（CA）。参考了文献Squeeze-and-Excitation
Networks中的SE块。</li>
</ol>
<h2 id="详细算法">详细算法</h2>
<h3 id="网络结构">网络结构</h3>
<figure>
<img src="image-RCAN.png" srcset="/img/loading.gif" lazyload alt="image-RCAN" />
<figcaption aria-hidden="true">image-RCAN</figcaption>
</figure>
<p>RCAN主要由四部分组成：</p>
<ol type="1">
<li>浅层特征提取</li>
<li>RIR深度特征提取</li>
<li>上采样模块</li>
<li>重建部分</li>
</ol>
<p><strong>浅层特征提取</strong></p>
<p>作者参考了之前论文的做法，用一层卷积层来提取浅层特征。</p>
<figure>
<img src="image-20230609173912082.png" srcset="/img/loading.gif" lazyload alt="image-20230609173912082" />
<figcaption aria-hidden="true">image-20230609173912082</figcaption>
</figure>
<p><span
class="math inline">\(F_0\)</span>表示浅层特征提取之后得到的特征图，<span
class="math inline">\(H_{SF}()\)</span> 表示浅层特征提取，<span
class="math inline">\(I_{LR}\)</span>表示输入的低分辨率图像。</p>
<p><strong>RIR深度特征提取</strong></p>
<figure>
<img src="image-20230609174314668.png" srcset="/img/loading.gif" lazyload alt="image-20230609174314668" />
<figcaption aria-hidden="true">image-20230609174314668</figcaption>
</figure>
<p>这里的<span class="math inline">\(F_{DF}\)</span>
为RIR深度特征提取的输出，<span
class="math inline">\(F_g\)</span>表示第g个RG块的输出 ，<span
class="math inline">\(F_{g,b}\)</span>
为第g个RG块中的第b个RCAB块的输出。</p>
<p>从上一步的浅层特征提取中得到了特征图<span
class="math inline">\(F_0\)</span>
，之后作为输入进入到RIR深度特征提取部分。</p>
<p>这部分是一个嵌套结构。</p>
<p>这部分包含G个RG块和一个长跳连接（LSC），经过最后一个RG模块后还要经过一层卷积层之后与<span
class="math inline">\(F_0\)</span>做对应元素求和。（这里增加一层卷积层的作用我自己认为是为了让这个嵌套结构增加更多的可学习的部分，从而获得更多的灵活性。）</p>
<p>其中每一个RG块包含了B个RCAB块和一个短跳连接（SSC），并且经过最后一个RCAB块之后也有一层卷积层之后与输入做对应元素求和。</p>
<figure>
<img src="image-20230609175456667.png" srcset="/img/loading.gif" lazyload alt="image-20230609175456667" />
<figcaption aria-hidden="true">image-20230609175456667</figcaption>
</figure>
<p>上图是RCAB的内部结构。虚线框内是通道注意力机制（CA），虚线框外是类似残差块结构。上述的LSC，SSC，残差块中的shortcut共同使得RCAN能够过滤掉一些低频信息，并且一定程度上避免了网络退化和梯度消失/爆炸问题的出现。</p>
<p>到这里就分析完了残差嵌套结构，下面着重分析通道注意力机制。</p>
<p><strong>CA机制</strong></p>
<p>之所以提出CA机制，是因为作者注意到两个问题：</p>
<ol type="1">
<li>LR空间中的有很多低频信息和高频信息，低频的信息看起来更平坦，高频的信息通常是充满边缘、纹理等细节的区域。</li>
<li>卷积层的每一个卷积核都有自己的感受野，所以卷积后的输出是没办法利用感受野之外的上下文信息的。</li>
</ol>
<p>作者根据对以上问题的分析，所以引入了SE块来调整不同的通道权重，从而让含有更多高频信息的通道在参与训练时以更加重要的身份参与就是指更大的权重。</p>
<figure>
<img src="image-20230609180502114.png" srcset="/img/loading.gif" lazyload alt="image-20230609180502114" />
<figcaption aria-hidden="true">image-20230609180502114</figcaption>
</figure>
<p>左侧是输入的特征图（<span
class="math inline">\(H*W*C\)</span>），右侧是经过加权之后的特征图。</p>
<p>第一步是Squeeze操作，通过全局平均池化操作：</p>
<figure>
<img src="image-20230609180843475.png" srcset="/img/loading.gif" lazyload alt="image-20230609180843475" />
<figcaption aria-hidden="true">image-20230609180843475</figcaption>
</figure>
<p>对每一个通道产生一个通道描述符。这样做的目的在于将全局的信息压缩到一起，增强了对全局信息的把握，让较低的层也能利用到更大范围的信息。</p>
<p>如果一个通道包含的高频信息越多，则获取到的通道描述符<span
class="math inline">\(z_c\)</span>
也就越大。这样就能对不同的通道有了不同的权值。但是这样做的缺点是，上述的步骤只是做了简单的求解平均值，是没有通过学习得到的，这样就会使得<span
class="math inline">\(z_c\)</span>是不变且独立的，这样的网络并不灵活。</p>
<p>为了获取通道间的非互斥关系，以及让CA机制变得可学习。作者提出了一个简单的门机制。</p>
<figure>
<img src="image-20230609181422088.png" srcset="/img/loading.gif" lazyload alt="image-20230609181422088" />
<figcaption aria-hidden="true">image-20230609181422088</figcaption>
</figure>
<p>通过对上一步获取的各个通道的<span class="math inline">\(z\)</span>
进行降维操作，降到<span class="math inline">\(\frac{C}{r}\)</span>
维。之后通过ReLU激活函数来获取非线性关系。然会恢复维度。最后通过sigmod激活函数控制每个通道的激励。从而得到各个通道的权重。</p>
<p><strong>上采样和重建</strong></p>
<p>经过了RIR深度特征提取之后的FDF作为上采样模块的输入，进行上采样，把粗分辨率特征提升到高分辨率特征。重建部分采用3个3<em>3</em>C卷积核进行重建。最后作者为了RCAN网络跟先前的网络作比较，于是选择了同样的损失函数来优化模型。优化器选择的是Adam优化器。</p>
<figure>
<img src="image-20230611152739652.png" srcset="/img/loading.gif" lazyload alt="image-20230611152739652" />
<figcaption aria-hidden="true">image-20230611152739652</figcaption>
</figure>
<h2 id="实验">实验</h2>
<p><em>实验环节的结论，仅代表我个人的看法。我只是一个初学者，很多定性结论的得出都是依靠直觉。还请各位批评指正。</em></p>
<p>实验一：去除RCAB块的CA layer。</p>
<p>实验方法：将RCAB块中的CA
layer去掉。其余网络结构与论文保持一致。训练500个epoch。</p>
<p>实验二：去除网络中的SSC和LSC。</p>
<p>实验方法：将网络中的SSC和LSC去掉。其余网络结构与论文保持一致。训练500个epoch。</p>
<p>实验三：利用反卷积进行上采样。</p>
<p>实验方法：用反卷积进行上采样。其余网络结构与论文保持一致。训练500个epoch。</p>
<p>​
利用上述三个实验训练出来的网络，处理Set5数据集，分别求PSNR，SSIM，明度、饱和度的平均值，得到以下数据。数据有改动，上次是直接对三通道求PSNR，SSIM。这次是单独对Y通道计算（与论文方法一致）。</p>
<p><strong>实验一</strong></p>
<table>

<thead>
<tr class="header">
<th></th>
<th><strong>HR</strong></th>
<th><strong>Base</strong></th>
<th><strong>No CA layer</strong></th>
<th><strong>No SSC LSC</strong></th>
<th><strong>Deconvolution</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>PSNR</td>
<td>inf</td>
<td>13.884</td>
<td>13.902</td>
<td><strong>16.274</strong></td>
<td>15.822</td>
</tr>
<tr class="even">
<td>SSIM</td>
<td>1</td>
<td>0.335</td>
<td>0.341</td>
<td><strong>0.378</strong></td>
<td>0.360</td>
</tr>
<tr class="odd">
<td>明度</td>
<td>133.31</td>
<td>118.72</td>
<td><strong>123.49</strong></td>
<td>122.90</td>
<td>116.85</td>
</tr>
<tr class="even">
<td>饱和度</td>
<td>125.88</td>
<td>43.24</td>
<td>49.41</td>
<td>58.96</td>
<td><strong>59.09</strong></td>
</tr>
</tbody>
</table>
<figure>
<img src="image-20230611152832760.png" srcset="/img/loading.gif" lazyload alt="image-20230611152832760" />
<figcaption aria-hidden="true">image-20230611152832760</figcaption>
</figure>
<p>​ 通过实验一(No CA
layer)与Base对比发现，去掉了通道注意力机制，对重建后的图像质量提升反而有一定的帮助，与论文中的实验结论相悖。另外去掉了通道注意力机制之后，同样进行500个epoch，训练时间大约缩短了20%。时间缩短的原因不难想出。去除了通道注意力机制之后，参数量减大大减少。参数量的减少带来了运算量的减少，所以训练时间与重建时间都会减少。</p>
<p>​ 效果变差的原因我认为是在进行计算通道表示符的时候，直接采用了global
pooling的方法将信息归一化至一个点，但是我认为特征图上的信息很大一部分靠位置来体现，这种全局池化的方式直接损失了位置信息。还有优化的空间。</p>
<p>​
颜色的信息也有损失，但是我觉着不必担心，因为通过不断最小化L1Loss函数，更新网络的参数，会实现跟HR尽可能相近的颜色和结构信息。</p>
<p><strong>实验二</strong></p>
<figure>
<img src="image-20230611152915204.png" srcset="/img/loading.gif" lazyload alt="image-20230611152915204" />
<figcaption aria-hidden="true">image-20230611152915204</figcaption>
</figure>
<p>蓝色线是实验二的结果，绿色线是Base的结果。</p>
<p>​
通过实验二与Base对比发现。在相同的迭代次数之下，实验二的loss值比base的高了大约11.3%。说明，SSC和LSC对加速训练有很大的影响。根据这个loss函数结果的不同，也能解释出实验三PSNR，SSIM更好的原因。因为训练效果不好，网络的主体权重还没怎么起作用，此时重建后图片的质量受上采样影响更大。另外通过对同一次训练不同时候取得的模型观测可以佐证这个结论。</p>
<figure>
<img src="image-20230611153000026.png" srcset="/img/loading.gif" lazyload alt="image-20230611153000026" />
<figcaption aria-hidden="true">image-20230611153000026</figcaption>
</figure>
<p>​
此时训练的迭代次数较少，导致网络主体对图像影响不大，而图像产生较好的结果的原因是，上采样LR图像重建后的结果。</p>
<p><strong>实验三</strong></p>
<figure>
<img src="image-20230611153017387.png" srcset="/img/loading.gif" lazyload alt="image-20230611153017387" />
<figcaption aria-hidden="true">image-20230611153017387</figcaption>
</figure>
<p>​
之所以做实验三，是因为我发现，重建后的图像会出现九宫格。起初我认为是data
loader有问题，修改之后问题仍然存在。后面发现随着迭代次数的增加，九宫格的线会渐渐变细。因此我认为是网络中的一部分出了问题。又因为这个线出现的位置很特殊，每次总是把图像等分，所以我认为是上采样环节出了问题，所以采用反卷积代替的。但是代替后仍出现了九宫格。</p>
<p><strong>补充实验</strong></p>
<p>​
用十一张320*180的风景图像，五张较大的（长宽都超过1200像素）细节更多的建筑的图像，以及五张较大的颜色丰富的花朵图像，用BD方式下采样4倍，分别输入到上述得到的四个模型中，并求平均值，得到以下数据。</p>
<figure>
<img src="image-20230611153348034.png" srcset="/img/loading.gif" lazyload alt="image-20230611153348034" />
<figcaption aria-hidden="true">image-20230611153348034</figcaption>
</figure>
<p>​ 得到的数据跟上次的结果相近，大部分情况下都是实验二的效果最好</p>
<p>​
通过Flower与其他两组数据对比，发现Flower的SSIM指标很高。SSIM指标反映的是重建图像与HR图像在亮度、对比度和结构三方面的相似程度。所以我的想法是，分别求出上述四种种数据集在不同网络的HR图像和SR图像的亮度对比函数、对比度对比函数、结构相关系数，求取平均值，经过对比就能发现RCAN网络的短板。从而想办法去加强。</p>
<p>根据SSIM指标的计算公式，分别对上述几个数据集求L（Luminance
亮度）C（Contrast 对比度）S（Structure 结构）</p>
<figure>
<img src="image-20230611153554031.png" srcset="/img/loading.gif" lazyload alt="image-20230611153554031" />
<figcaption aria-hidden="true">image-20230611153554031</figcaption>
</figure>
<p>​
经过数据集间相互对比发现，Flower的SSIM的指标更高的原因在于S复原的更好。另外在其他数据集中发现，L复原的效果最好，一般情况下S、C还有进步空间。</p>
<p>​ 下面是效果展示。（图像尺寸有修改）</p>
<p>​ 因为人类视觉局部性的特点
所以实际求SSIM是，SSIM在实际实现中是利用的是一个窗口在整个图像上逐像素移动。局部求解SSIM然后再利用高斯加权函数避免分块效应，再求取平均值作为全局的SSIM。所以通过上述算出的L、S、C相乘得到的SSIM与表格中的SSIM有出入。但是上述的L、S、C也可以大致反映出网络在这三个层面的表现。</p>
<figure>
<img src="image-20230611153627432.png" srcset="/img/loading.gif" lazyload alt="image-20230611153627432" />
<figcaption aria-hidden="true">image-20230611153627432</figcaption>
</figure>
<figure>
<img src="image-20230611153654173.png" srcset="/img/loading.gif" lazyload alt="image-20230611153654173" />
<figcaption aria-hidden="true">image-20230611153654173</figcaption>
</figure>
<figure>
<img src="image-20230611153658316.png" srcset="/img/loading.gif" lazyload alt="image-20230611153658316" />
<figcaption aria-hidden="true">image-20230611153658316</figcaption>
</figure>
<figure>
<img src="image-20230611153702383.png" srcset="/img/loading.gif" lazyload alt="image-20230611153702383" />
<figcaption aria-hidden="true">image-20230611153702383</figcaption>
</figure>
<figure>
<img src="image-20230611153706621.png" srcset="/img/loading.gif" lazyload alt="image-20230611153706621" />
<figcaption aria-hidden="true">image-20230611153706621</figcaption>
</figure>
<figure>
<img src="image-20230611153712884.png" srcset="/img/loading.gif" lazyload alt="image-20230611153712884" />
<figcaption aria-hidden="true">image-20230611153712884</figcaption>
</figure>
<figure>
<img src="image-20230611153720505.png" srcset="/img/loading.gif" lazyload alt="image-20230611153720505" />
<figcaption aria-hidden="true">image-20230611153720505</figcaption>
</figure>
<figure>
<img src="image-20230611153724001.png" srcset="/img/loading.gif" lazyload alt="image-20230611153724001" />
<figcaption aria-hidden="true">image-20230611153724001</figcaption>
</figure>
<figure>
<img src="image-20230611153727546.png" srcset="/img/loading.gif" lazyload alt="image-20230611153727546" />
<figcaption aria-hidden="true">image-20230611153727546</figcaption>
</figure>
<figure>
<img src="image-20230611153731936.png" srcset="/img/loading.gif" lazyload alt="image-20230611153731936" />
<figcaption aria-hidden="true">image-20230611153731936</figcaption>
</figure>
<figure>
<img src="image-20230611153734640.png" srcset="/img/loading.gif" lazyload alt="image-20230611153734640" />
<figcaption aria-hidden="true">image-20230611153734640</figcaption>
</figure>
<figure>
<img src="image-20230611153738113.png" srcset="/img/loading.gif" lazyload alt="image-20230611153738113" />
<figcaption aria-hidden="true">image-20230611153738113</figcaption>
</figure>
<p>​
通过Flower_LR与其他LR对比发现，前者图像更加简洁，后者的图像中有很多细节信息，我想这是导致SSIM指标不同的主要原因。</p>
<p>​
另外重建出的Set5、landscape与重建出的Building、Flower对比发现，较大的图像重建出来九宫格现象就很浅，较小的图像的九宫格就比较明显。通过这点我认为九宫格的出现跟卷积核的大小与输入图像的尺寸的比例有关系。输入的尺寸较小时，卷积核的感受野占比就更大，提取特征时就会提取不到更多的细节特征，另外在重建时，卷积和尺寸也较大，也会忽略一部分细节信息。</p>
<h2 id="结论">结论</h2>
<p>​
关于实验一的结果与论文相悖，我认为是训练迭代次数太少了（因为算力的问题，没有训练到模型收敛）。通过实验一，我认为这里的通道注意力机制像是锦上添花的部分，因为网络在收敛之前，重建的图像质量波动较大，所以在网络还没有收敛之前很难体现这里通道注意力的作用。所以才得出了与论文相悖的结论。另外在通道注意力机制中，全局平均池化操作仍有优化的可能。</p>
<p>​
实验二，发现SSC和LSC在网络的训练中起着重要的作用，能以较大幅度加速训练过程。另外类似残差的结构能使网络扩展更多层而不出现梯度和消失梯度爆炸。</p>
<p>​
实验三，最后还是留下了九宫格的问题，不过根据目前的趋势，我认为随着训练的进行可能会九宫格会消失。因为神经网络具有学习能力，通过调整参数会慢慢淡化九宫格。</p>
<p>​
通过其他测试集的实验，发现网络在重建图像的对比度和结构还存在问题。另外就是九宫格的出现与输入图像的尺寸和卷积核的大小的比例有关。</p>

                
              </div>
            
            <hr/>
            <div>
              <div class="post-metas my-3">
  
    <div class="post-meta mr-3 d-flex align-items-center">
      <i class="iconfont icon-category"></i>
      

<span class="category-chains">
  
  
    
      <span class="category-chain">
        
  <a href="/categories/%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB/" class="category-chain-item">论文精读</a>
  
  

      </span>
    
  
</span>

    </div>
  
  
    <div class="post-meta">
      <i class="iconfont icon-tags"></i>
      
        <a href="/tags/RCAN%E5%8D%95%E5%B9%85%E5%9B%BE%E5%83%8F%E8%B6%85%E5%88%86%E8%BE%A8%E7%8E%87/">#RCAN单幅图像超分辨率</a>
      
    </div>
  
</div>


              
  

  <div class="license-box my-3">
    <div class="license-title">
      <div>Image Super-Resolution Using Very Deep Residual Channel Attention Networks 精读笔记</div>
      <div>https://pixelpilot666.github.io/2023/06/09/Image-Super-Resolution-Using-Very-Deep-Residual-Channel-Attention-Networks-精读笔记/</div>
    </div>
    <div class="license-meta">
      
        <div class="license-meta-item">
          <div>作者</div>
          <div>PixelPilot</div>
        </div>
      
      
        <div class="license-meta-item license-meta-date">
          <div>发布于</div>
          <div>2023年6月9日</div>
        </div>
      
      
      
        <div class="license-meta-item">
          <div>许可协议</div>
          <div>
            
              
              
                <a target="_blank" href="https://creativecommons.org/licenses/by/4.0/">
                  <span class="hint--top hint--rounded" aria-label="BY - 署名">
                    <i class="iconfont icon-by"></i>
                  </span>
                </a>
              
            
          </div>
        </div>
      
    </div>
    <div class="license-icon iconfont"></div>
  </div>



              
                <div class="post-prevnext my-3">
                  <article class="post-prev col-6">
                    
                    
                      <a href="/2023/06/11/Robust-Rcovery-of-Subspace-Structure-by-Low-Rank-Representation%E7%B2%BE%E8%AF%BB%E7%AC%94%E8%AE%B0/" title="Robust-Rcovery-of-Subspace-Structure-by-Low-Rank-Representation精读笔记">
                        <i class="iconfont icon-arrowleft"></i>
                        <span class="hidden-mobile">Robust-Rcovery-of-Subspace-Structure-by-Low-Rank-Representation精读笔记</span>
                        <span class="visible-mobile">上一篇</span>
                      </a>
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                  </article>
                </div>
              
            </div>

            
  
  
    <article id="comments" lazyload>
      
  <div id="valine"></div>
  <script type="text/javascript">
    Fluid.utils.loadComments('#valine', function() {
      Fluid.utils.createScript('https://lib.baomitu.com/valine/1.5.1/Valine.min.js', function() {
        var options = Object.assign(
          {"appId":"2yoCLZjZLSAUgnMqvJ5vzl0I-gzGzoHsz","appKey":"TAADaGFWou9xASz6lIeA4JGy","path":"window.location.pathname","placeholder":null,"avatar":"retro","meta":[],"requiredFields":[],"pageSize":10,"lang":"zh-CN","highlight":true,"recordIP":false,"serverURLs":"","emojiCDN":null,"emojiMaps":null,"enableQQ":false},
          {
            el: "#valine",
            path: window.location.pathname
          }
        )
        new Valine(options);
        Fluid.utils.waitElementVisible('#valine .vcontent', () => {
          var imgSelector = '#valine .vcontent img:not(.vemoji)';
          Fluid.plugins.imageCaption(imgSelector);
          Fluid.plugins.fancyBox(imgSelector);
        })
      });
    });
  </script>
  <noscript>Please enable JavaScript to view the comments</noscript>


    </article>
  


          </article>
        </div>
      </div>
    </div>

    <div class="side-col d-none d-lg-block col-lg-2">
      
  <aside class="sidebar" style="margin-left: -1rem">
    <div id="toc">
  <p class="toc-header">
    <i class="iconfont icon-list"></i>
    <span>目录</span>
  </p>
  <div class="toc-body" id="toc-body"></div>
</div>



  </aside>


    </div>
  </div>
</div>





  



  



  



  



  


  
  









    

    
      <a id="scroll-top-button" aria-label="TOP" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v" for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>

    

    
  </main>

  <footer>
    <div class="footer-inner">
  
    <div class="footer-content">
       <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a> 
    </div>
  
  
    <div class="statistics">
  
  

  
    
      <span id="leancloud-site-pv-container" style="display: none">
        总访问量 
        <span id="leancloud-site-pv"></span>
         次
      </span>
    
    
      <span id="leancloud-site-uv-container" style="display: none">
        总访客数 
        <span id="leancloud-site-uv"></span>
         人
      </span>
    
    

  
</div>

  
  
  
</div>

  </footer>

  <!-- Scripts -->
  
  <script  src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://lib.baomitu.com/jquery/3.6.0/jquery.min.js" ></script>
<script  src="https://lib.baomitu.com/twitter-bootstrap/4.6.1/js/bootstrap.min.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>


  <script  src="https://lib.baomitu.com/typed.js/2.0.12/typed.min.js" ></script>
  <script>
    (function (window, document) {
      var typing = Fluid.plugins.typing;
      var subtitle = document.getElementById('subtitle');
      if (!subtitle || !typing) {
        return;
      }
      var text = subtitle.getAttribute('data-typed-text');
      
        typing(text);
      
    })(window, document);
  </script>




  
    <script  src="/js/img-lazyload.js" ></script>
  




  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/tocbot/4.18.2/tocbot.min.js', function() {
    var toc = jQuery('#toc');
    if (toc.length === 0 || !window.tocbot) { return; }
    var boardCtn = jQuery('#board-ctn');
    var boardTop = boardCtn.offset().top;

    window.tocbot.init(Object.assign({
      tocSelector     : '#toc-body',
      contentSelector : '.markdown-body',
      linkClass       : 'tocbot-link',
      activeLinkClass : 'tocbot-active-link',
      listClass       : 'tocbot-list',
      isCollapsedClass: 'tocbot-is-collapsed',
      collapsibleClass: 'tocbot-is-collapsible',
      scrollSmooth    : true,
      includeTitleTags: true,
      headingsOffset  : -boardTop,
    }, CONFIG.toc));
    if (toc.find('.toc-list-item').length > 0) {
      toc.css('visibility', 'visible');
    }

    Fluid.events.registerRefreshCallback(function() {
      if ('tocbot' in window) {
        tocbot.refresh();
        var toc = jQuery('#toc');
        if (toc.length === 0 || !tocbot) {
          return;
        }
        if (toc.find('.toc-list-item').length > 0) {
          toc.css('visibility', 'visible');
        }
      }
    });
  });
</script>


  <script src=https://lib.baomitu.com/clipboard.js/2.0.11/clipboard.min.js></script>

  <script>Fluid.plugins.codeWidget();</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/anchor-js/4.3.1/anchor.min.js', function() {
    window.anchors.options = {
      placement: CONFIG.anchorjs.placement,
      visible  : CONFIG.anchorjs.visible
    };
    if (CONFIG.anchorjs.icon) {
      window.anchors.options.icon = CONFIG.anchorjs.icon;
    }
    var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
    var res = [];
    for (var item of el) {
      res.push('.markdown-body > ' + item.trim());
    }
    if (CONFIG.anchorjs.placement === 'left') {
      window.anchors.options.class = 'anchorjs-link-left';
    }
    window.anchors.add(res.join(', '));

    Fluid.events.registerRefreshCallback(function() {
      if ('anchors' in window) {
        anchors.removeAll();
        var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
        var res = [];
        for (var item of el) {
          res.push('.markdown-body > ' + item.trim());
        }
        if (CONFIG.anchorjs.placement === 'left') {
          anchors.options.class = 'anchorjs-link-left';
        }
        anchors.add(res.join(', '));
      }
    });
  });
</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js', function() {
    Fluid.plugins.fancyBox();
  });
</script>


  <script>Fluid.plugins.imageCaption();</script>

  
      <script>
        if (!window.MathJax) {
          window.MathJax = {
            tex    : {
              inlineMath: { '[+]': [['$', '$']] }
            },
            loader : {
              load: ['ui/lazy']
            },
            options: {
              renderActions: {
                insertedScript: [200, () => {
                  document.querySelectorAll('mjx-container').forEach(node => {
                    let target = node.parentNode;
                    if (target.nodeName.toLowerCase() === 'li') {
                      target.parentNode.classList.add('has-jax');
                    }
                  });
                }, '', false]
              }
            }
          };
        } else {
          MathJax.startup.document.state(0);
          MathJax.texReset();
          MathJax.typeset();
          MathJax.typesetPromise();
        }

        Fluid.events.registerRefreshCallback(function() {
          if ('MathJax' in window && MathJax.startup.document && typeof MathJax.startup.document.state === 'function') {
            MathJax.startup.document.state(0);
            MathJax.texReset();
            MathJax.typeset();
            MathJax.typesetPromise();
          }
        });
      </script>
    

  <script  src="https://lib.baomitu.com/mathjax/3.2.2/es5/tex-mml-chtml.js" ></script>

  <script defer src="/js/leancloud.js" ></script>

  <script  src="/js/local-search.js" ></script>

  <script defer src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" ></script>





<!-- 主题的启动项，将它保持在最底部 -->
<!-- the boot of the theme, keep it at the bottom -->
<script  src="/js/boot.js" ></script>


  

  <noscript>
    <div class="noscript-warning">博客在允许 JavaScript 运行的环境下浏览效果更佳</div>
  </noscript>
</body>
</html>
