<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>Robust-Rcovery-of-Subspace-Structure-by-Low-Rank-Representation精读笔记</title>
    <link href="/2023/06/11/Robust-Rcovery-of-Subspace-Structure-by-Low-Rank-Representation%E7%B2%BE%E8%AF%BB%E7%AC%94%E8%AE%B0/"/>
    <url>/2023/06/11/Robust-Rcovery-of-Subspace-Structure-by-Low-Rank-Representation%E7%B2%BE%E8%AF%BB%E7%AC%94%E8%AE%B0/</url>
    
    <content type="html"><![CDATA[<h1id="robust-rcovery-of-subspace-structure-by-low-rank-representation精读笔记">Robust-Rcovery-of-Subspace-Structure-by-Low-Rank-Representation精读笔记</h1><h2 id="背景">背景</h2><p>论文链接：<ahref="https://arxiv.org/pdf/1010.2955.pdf">Robust-Rcovery-of-Subspace-Structure-by-Low-Rank-Representation</a></p><p>RPCA（鲁棒主成分分析）把一个观测到的数据分解成一个干净的数据矩阵和一个稀疏的噪声矩阵的和的形式。<span class="math display">\[X = D + E\]</span> 其中<span class="math inline">\(X\)</span>是观测数据，<spanclass="math inline">\(D\)</span>是要恢复的矩阵，<spanclass="math inline">\(E\)</span>是稀疏的噪声矩阵。</p><p>因为一个好的图像往往是低秩的，因为高质量的图像往往是平滑的，行与行之间往往是线性相关的，这样就会出现低秩。所以<spanclass="math inline">\(D\)</span>是一个低秩的矩阵。</p><p>可以通过秩最小化，来恢复出低秩矩阵<spanclass="math inline">\(D\)</span>。 <span class="math display">\[\min_{D,\ E}\ rank(D) + \lambda||E||_l, \qquad s.t.X = D + E\]</span> 取得令上述取最小值的<span class="math inline">\(D^*,\E^*\)</span> 就得到了低秩矩阵和离散的噪声矩阵。</p><p>上述的方法就是RPCA的主要思想。</p><p>这个方法有一个问题，现实中潜在的数据结构往往来自于多个子空间，但是上述的方法是基于数据的结构只是来自于一个子空间。这就会导致恢复出来的数据不精准。</p><h2 id="解决措施">解决措施</h2><p>为了解决这个问题，作者引入了字典<spanclass="math inline">\(A\)</span>，用<spanclass="math inline">\(AZ\)</span>来表示低秩矩阵，这样就能把这个低秩矩阵看作是多个子空间的线性组合。<span class="math display">\[\min_{Z,\ E}\ rank(Z) + \lambda||E||_l, \qquad s.t.X=AZ+E\]</span> 取令上述公式取得最小值时的<span class="math inline">\(Z^*, \E^*\)</span>，由矩阵乘法的性质得出，<spanclass="math inline">\(rank(AZ^*) &lt; rank(Z^*)\)</span>，所以恢复出来的矩阵，仍是低秩矩阵。</p><p>另外通过取字典<span class="math inline">\(A = I\)</span>（<spanclass="math inline">\(I\)</span>表示单位阵）则就是RPCA的方法。所以这里可以看作是RPCA的一个推广。</p><h2 id="详细算法">详细算法</h2><p><strong>低秩表示</strong></p><p>因为秩函数不是唯一解，但是在一定条件下，核范数是秩函数的最佳凸松弛。而且作者想要处理的图像主要包含特定值缺失这种类型的错误。所以选择了<spanclass="math inline">\(l_{2,1}\)</span> 。 <span class="math display">\[\min_{Z,\ E}\ rank(Z) + \lambda||E||_{2,1}, \qquad s.t. X = AZ + E\]</span> 作者使用不精确拉格朗日乘子法（InexactALM）也叫交替方向乘子法（ADMM）来求最小值点。</p><p><em>交替方向乘子法（Alternating Direction Method ofMultipliers）通常用于解决存在两个优化变量的只含等式约束的优化类问题</em></p><p>首先引入松弛变量<spanclass="math inline">\(J\)</span>，便于用Singular Value Thresholding（SVT奇异阈值法）求解<spanclass="math inline">\(Z\)</span>，使得下面单独优化<spanclass="math inline">\(Z\)</span>时，关于<spanclass="math inline">\(Z\)</span>的损失函数足够简单。</p><p><em>这里可以参考了一篇博客<ahref="https://lee-plus-plus.github.io/2023/03/06/optimization_1/">凸优化实战1</a>来理解<spanclass="math inline">\(J\)</span>的作用。</em></p><p>然后写出增广拉格朗日函数： <span class="math display">\[L = ||J||_* + \lambda||E||_{2,1} + tr(Y_1^T(X - AZ - E)) +tr(Y_2^T(Z-J)) + \frac{\mu}{2}(||X-AZ-E||_F^2 + ||Z-J||_F^2)\]</span> 然后按照下列步骤逐渐迭代得出<span class="math inline">\(Z^*,E^*\)</span> 。</p><figure><img src="image-20230611204449400.png" alt="image-20230611204449400" /><figcaption aria-hidden="true">image-20230611204449400</figcaption></figure><p>Step 1可由SVT（奇异值阈值）求解。</p><p>Step 3用以下引理求解。</p><figure><img src="image-20230611205110914.png" alt="image-20230611205110914" /><figcaption aria-hidden="true">image-20230611205110914</figcaption></figure><p><strong>子空间分割</strong></p><p>通过上述步骤获得了<span class="math inline">\(Z^*,\  E^*\)</span>。通过下列步骤获取亲和矩阵<spanclass="math inline">\(W\)</span>，之后把亲和矩阵放入谱聚类算法分割成k类。</p><figure><img src="image-20230611204520431.png" alt="image-20230611204520431" /><figcaption aria-hidden="true">image-20230611204520431</figcaption></figure><p><strong>估计子空间数目</strong></p><p>获取了亲和矩阵<spanclass="math inline">\(W\)</span>之后，根据下列步骤得出对称归一化拉普拉斯矩阵。</p><figure><img src="image-20230611205443740.png" alt="image-20230611205443740" /><figcaption aria-hidden="true">image-20230611205443740</figcaption></figure><p>拉普拉斯矩阵是半正定矩阵，有m个非负特征值。利用它的性质——特征值为0的重数等于图连通分量的个数，来估计子空间数目。</p><p>但是低秩矩阵多少存在些噪声。所以提出了如下的软阈值算法来估计特征值近似0的重数，来估计子空间数目。</p><figure><img src="image-20230611205746804.png" alt="image-20230611205746804" /><figcaption aria-hidden="true">image-20230611205746804</figcaption></figure><p>这里的<spanclass="math inline">\(n\)</span>表示样本个数。这里的样本数目指的是行向量的个数，因为这里的子空间指的是行空间。</p><p><strong>离群值检测</strong></p><p>离群值检测有两个方法</p><ol type="1"><li><p>通过获取的<spanclass="math inline">\(E^*\)</span>的非零列来检测：</p><p>当<span class="math inline">\(||E||_{:,i} &gt;\tau\)</span>时，X的第i个分量被视为离群值。</p></li><li><p>通过亲和值来检测：</p><p>亲和度为0或者接近0的分量，被视为离群值。</p></li></ol><h2 id="实验">实验</h2><p><em>本人是一个刚入门的初学者，有很多地方表述不到位，另外有些结论的得出是根据直觉。如有不严谨的地方，请批评指正。</em></p><p><strong>低秩恢复</strong></p><p>这里我找了一些有一些强烈噪声的图像作为观测矩阵。分别使用RPCA和LRR算法处理。</p><figure><img src="image-20230611211625113.png" alt="image-20230611211625113" /><figcaption aria-hidden="true">image-20230611211625113</figcaption></figure><figure><img src="image-20230611211638589.png" alt="image-20230611211638589" /><figcaption aria-hidden="true">image-20230611211638589</figcaption></figure><figure><img src="image-20230611211657415.png" alt="image-20230611211657415" /><figcaption aria-hidden="true">image-20230611211657415</figcaption></figure><figure><img src="image-20230611211711964.png" alt="image-20230611211711964" /><figcaption aria-hidden="true">image-20230611211711964</figcaption></figure><figure><img src="image-20230611211722625.png" alt="image-20230611211722625" /><figcaption aria-hidden="true">image-20230611211722625</figcaption></figure><p>​通过实验四，我观察到RPCA在去除噪声的同时也会将图像上的一些信息也会去掉。LRR只是会去掉一些横竖向的噪点，不能恢复较为明显的损坏。</p><p>​首先RPCA会出现上述结果的原因，是RPCA基于潜在的数据的结构只来自一个低秩子空间。所以恢复的低秩矩阵只会保留较大的子空间，也就是大面积的结构相似的部分，因为只有这样行向量之间线性相关程度更高，所以秩也就越低。因此就会去除很多图像原本包含的信息。</p><p>​反观LRR，LRR在设计的时候针对上述问题做了改进，引入了字典A，让低秩矩阵表示为多个子空间的线性组合，这样就使得恢复出来的低秩矩阵可以包含较多子空间的信息，使得观测矩阵的大部分结构都得以保留。但是如果噪声较强，则仍可能保留噪声。</p><p><strong>验证对图像结构的影响</strong></p><p>我用Set5数据集，随机对一些行和列产生缺失，来制作噪声图像。然后分别用RPCA和LRR处理。</p><figure><img src="image-20230611212207401.png" alt="image-20230611212207401" /><figcaption aria-hidden="true">image-20230611212207401</figcaption></figure><figure><img src="image-20230611212217575.png" alt="image-20230611212217575" /><figcaption aria-hidden="true">image-20230611212217575</figcaption></figure><figure><img src="image-20230611212228215.png" alt="image-20230611212228215" /><figcaption aria-hidden="true">image-20230611212228215</figcaption></figure><figure><img src="image-20230611212241343.png" alt="image-20230611212241343" /><figcaption aria-hidden="true">image-20230611212241343</figcaption></figure><figure><img src="image-20230611212256015.png" alt="image-20230611212256015" /><figcaption aria-hidden="true">image-20230611212256015</figcaption></figure><p>​通过实验五，发现RPCA处理过的图像的SSIM和PSNR都有明显的下降，说明RPCA在去除噪声的同时对图像原本的结构也有破坏，而LRR处理之后的图像SSIM与观测图像几乎相同，PSNR在有些情况下还有小幅提升。</p><p><strong>验证<spanclass="math inline">\(\lambda\)</span>的取值对结果的影响</strong></p><p>输入仍是被处理过的Set 5数据集。<span class="math inline">\(\lambda =[0.01, 0.50,1.10,4.10]\)</span></p><figure><img src="image-20230611212524674.png" alt="image-20230611212524674" /><figcaption aria-hidden="true">image-20230611212524674</figcaption></figure><figure><img src="image-20230611212538141.png" alt="image-20230611212538141" /><figcaption aria-hidden="true">image-20230611212538141</figcaption></figure><figure><img src="image-20230611212600154.png" alt="image-20230611212600154" /><figcaption aria-hidden="true">image-20230611212600154</figcaption></figure><figure><img src="image-20230611212610393.png" alt="image-20230611212610393" /><figcaption aria-hidden="true">image-20230611212610393</figcaption></figure><figure><img src="image-20230611212718429.png" alt="image-20230611212718429" /><figcaption aria-hidden="true">image-20230611212718429</figcaption></figure><p>​ 经过对不同的<span class="math inline">\(\lambda\)</span>产生的结果对比，发现LRR算法对参数不敏感，<spanclass="math inline">\(\lambda\)</span>对恢复出的图像质量影响不大。噪声图像差别较大的原因，是在获取了噪声图像之后，进行了归一化操作。我认为对<spanclass="math inline">\(\lambda\)</span>不敏感的原因在于字典的选择，因为字典<spanclass="math inline">\(A\)</span>是来自<spanclass="math inline">\(X\)</span>。</p><table><thead><tr class="header"><th><strong>耗时（S）</strong></th><th><strong>LRR</strong></th><th><strong>RPCA</strong></th></tr></thead><tbody><tr class="odd"><td>Baby</td><td>140.211</td><td>9.995</td></tr><tr class="even"><td>Bird</td><td>50.88</td><td>2.019</td></tr><tr class="odd"><td>Head</td><td>49.015</td><td>1.985</td></tr><tr class="even"><td>Woman</td><td>36.01</td><td>1.786</td></tr><tr class="odd"><td>Butterfly</td><td>46.08</td><td>1.883</td></tr></tbody></table><p>​ LRR处理一幅较大的彩色图像的时间远大于RPCA处理的时间。</p><p><strong>自带噪声的图像恢复</strong></p><p>这里的数据是来自几个常见的人脸数据集。</p><figure><img src="image-20230611213022429.png" alt="image-20230611213022429" /><figcaption aria-hidden="true">image-20230611213022429</figcaption></figure><figure><img src="image-20230611213037306.png" alt="image-20230611213037306" /><figcaption aria-hidden="true">image-20230611213037306</figcaption></figure><figure><img src="image-20230611213048119.png" alt="image-20230611213048119" /><figcaption aria-hidden="true">image-20230611213048119</figcaption></figure><figure><img src="image-20230611213057268.png" alt="image-20230611213057268" /><figcaption aria-hidden="true">image-20230611213057268</figcaption></figure><figure><img src="image-20230611213106314.png" alt="image-20230611213106314" /><figcaption aria-hidden="true">image-20230611213106314</figcaption></figure><p>​通过实验七发现，LRR在恢复图像清晰度方面，比RPCA效果好很多。LRR和RPCA在调整图像过曝或过暗方面都有一定的效果，但是通过观察对镜片反光这一现象处理的效果，发现LRR算法作用不大，RPCA能够去除反光的大部分影响。说明在处理严重缺失时，LRR算法还有进步的空间。</p><h2 id="结论">结论</h2><p>通过实验发现，LRR的优缺点如下：</p><p>优点：</p><ol type="1"><li>LRR算法恢复的低秩图像，能有效地保留图像的结构，能去除一部分噪声。</li><li>对<span class="math inline">\(\lambda\)</span>的选择不敏感，在<spanclass="math inline">\(\lambda\)</span>不同时，恢复出来的低秩图像质量差别不大。</li></ol><p>缺点：</p><ol type="1"><li>在噪声或者异常值严重的时候，无法正确去除。</li><li>处理图片时耗时较长。</li></ol>]]></content>
    
    
    <categories>
      
      <category>论文精读</category>
      
    </categories>
    
    
    <tags>
      
      <tag>LRR低秩表示</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Image Super-Resolution Using Very Deep Residual Channel Attention Networks 精读笔记</title>
    <link href="/2023/06/09/Image-Super-Resolution-Using-Very-Deep-Residual-Channel-Attention-Networks-%E7%B2%BE%E8%AF%BB%E7%AC%94%E8%AE%B0/"/>
    <url>/2023/06/09/Image-Super-Resolution-Using-Very-Deep-Residual-Channel-Attention-Networks-%E7%B2%BE%E8%AF%BB%E7%AC%94%E8%AE%B0/</url>
    
    <content type="html"><![CDATA[<h1id="image-super-resolution-using-very-deep-residual-channel-attention-networks-精读笔记">ImageSuper-Resolution Using Very Deep Residual Channel Attention Networks精读笔记</h1><h2 id="背景">背景</h2><p>这是一篇收录在ECCV2018的一篇单幅图像超分辨率论文</p><p>论文链接：<a href="https://arxiv.org/pdf/1807.02758.pdf">ImageSuper-Resolution Using Very Deep Residual Channel AttentionNetworks</a></p><p>这篇论文主要解决两个问题：</p><ol type="1"><li>CNN网络的深度对SR效果的提升有很大的影响，但是因为梯度消失、梯度爆炸、深度网络退化，所以用作SR的更深的卷积神经网络更难被训练。</li><li>低分辨率的输入和特征都包含了很多应该被舍弃的低频信息，但是这些低频信息却跟高频信息一样的重要程度去参与训练，这样就降低了CNN的表征能力。</li></ol><h2 id="解决措施">解决措施</h2><ol type="1"><li>为了解决更深的CNN难以训练，作者在网络中引入残差块，使得网络的深度大大增加。但是仅仅简单的叠加残差块，难以实现好的效果，所以作者提出了残差嵌套（RIR）结构，结构中的长跳链接（LSC）、短跳链接（SSC）以及残差块内的跨层链接都有助于绕过低频信息，让网络学习到更多的高频信息。</li><li>为了解决包含了更多高频信息的通道和包含了更多低频信息的通道以同样的重要程度参与训练的问题，作者引入了通道注意力机制（CA）。参考了文献Squeeze-and-ExcitationNetworks中的SE块。</li></ol><h2 id="详细算法">详细算法</h2><h3 id="网络结构">网络结构</h3><figure><img src="image-RCAN.png" alt="image-RCAN" /><figcaption aria-hidden="true">image-RCAN</figcaption></figure><p>RCAN主要由四部分组成：</p><ol type="1"><li>浅层特征提取</li><li>RIR深度特征提取</li><li>上采样模块</li><li>重建部分</li></ol><p><strong>浅层特征提取</strong></p><p>作者参考了之前论文的做法，用一层卷积层来提取浅层特征。</p><figure><img src="image-20230609173912082.png" alt="image-20230609173912082" /><figcaption aria-hidden="true">image-20230609173912082</figcaption></figure><p><spanclass="math inline">\(F_0\)</span>表示浅层特征提取之后得到的特征图，<spanclass="math inline">\(H_{SF}()\)</span> 表示浅层特征提取，<spanclass="math inline">\(I_{LR}\)</span>表示输入的低分辨率图像。</p><p><strong>RIR深度特征提取</strong></p><p><img src="image-20230609174314668.png" /></p><p>这里的<span class="math inline">\(F_{DF}\)</span>为RIR深度特征提取的输出，<spanclass="math inline">\(F_g\)</span>表示第g个RG块的输出 ，<spanclass="math inline">\(F_{g,b}\)</span>为第g个RG块中的第b个RCAB块的输出。</p><p>从上一步的浅层特征提取中得到了特征图<spanclass="math inline">\(F_0\)</span>，之后作为输入进入到RIR深度特征提取部分。</p><p>这部分是一个嵌套结构。</p><p>这部分包含G个RG块和一个长跳连接（LSC），经过最后一个RG模块后还要经过一层卷积层之后与<spanclass="math inline">\(F_0\)</span>做对应元素求和。（这里增加一层卷积层的作用我自己认为是为了让这个嵌套结构增加更多的可学习的部分，从而获得更多的灵活性。）</p><p>其中每一个RG块包含了B个RCAB块和一个短跳连接（SSC），并且经过最后一个RCAB块之后也有一层卷积层之后与输入做对应元素求和。</p><figure><img src="image-20230609175456667.png" alt="image-20230609175456667" /><figcaption aria-hidden="true">image-20230609175456667</figcaption></figure><p>上图是RCAB的内部结构。虚线框内是通道注意力机制（CA），虚线框外是类似残差块结构。上述的LSC，SSC，残差块中的shortcut共同使得RCAN能够过滤掉一些低频信息，并且一定程度上避免了网络退化和梯度消失/爆炸问题的出现。</p><p>到这里就分析完了残差嵌套结构，下面着重分析通道注意力机制。</p><p><strong>CA机制</strong></p><p>之所以提出CA机制，是因为作者注意到两个问题：</p><ol type="1"><li>LR空间中的有很多低频信息和高频信息，低频的信息看起来更平坦，高频的信息通常是充满边缘、纹理等细节的区域。</li><li>卷积层的每一个卷积核都有自己的感受野，所以卷积后的输出是没办法利用感受野之外的上下文信息的。</li></ol><p>作者根据对以上问题的分析，所以引入了SE块来调整不同的通道权重，从而让含有更多高频信息的通道在参与训练时以更加重要的身份参与就是指更大的权重。</p><figure><img src="image-20230609180502114.png" alt="image-20230609180502114" /><figcaption aria-hidden="true">image-20230609180502114</figcaption></figure><p>左侧是输入的特征图（<spanclass="math inline">\(H*W*C\)</span>），右侧是经过加权之后的特征图。</p><p>第一步是Squeeze操作，通过全局平均池化操作：</p><figure><img src="image-20230609180843475.png" alt="image-20230609180843475" /><figcaption aria-hidden="true">image-20230609180843475</figcaption></figure><p>对每一个通道产生一个通道描述符。这样做的目的在于将全局的信息压缩到一起，增强了对全局信息的把握，让较低的层也能利用到更大范围的信息。</p><p>如果一个通道包含的高频信息越多，则获取到的通道描述符<spanclass="math inline">\(z_c\)</span>也就越大。这样就能对不同的通道有了不同的权值。但是这样做的缺点是，上述的步骤只是做了简单的求解平均值，是没有通过学习得到的，这样就会使得<spanclass="math inline">\(z_c\)</span>是不变且独立的，这样的网络并不灵活。</p><p>为了获取通道间的非互斥关系，以及让CA机制变得可学习。作者提出了一个简单的门机制。</p><figure><img src="image-20230609181422088.png" alt="image-20230609181422088" /><figcaption aria-hidden="true">image-20230609181422088</figcaption></figure><p>通过对上一步获取的各个通道的<span class="math inline">\(z\)</span>进行降维操作，降到<span class="math inline">\(\frac{C}{r}\)</span>维。之后通过ReLU激活函数来获取非线性关系。然会恢复维度。最后通过sigmod激活函数控制每个通道的激励。从而得到各个通道的权重。</p><p><strong>上采样和重建</strong></p><p>经过了RIR深度特征提取之后的FDF作为上采样模块的输入，进行上采样，把粗分辨率特征提升到高分辨率特征。重建部分采用3个3<em>3</em>C卷积核进行重建。最后作者为了RCAN网络跟先前的网络作比较，于是选择了同样的损失函数来优化模型。优化器选择的是Adam优化器。</p><figure><img src="image-20230611152739652.png" alt="image-20230611152739652" /><figcaption aria-hidden="true">image-20230611152739652</figcaption></figure><h2 id="实验">实验</h2><p><em>实验环节的结论，仅代表我个人的看法。我只是一个初学者，很多定性结论的得出都是依靠直觉。还请各位批评指正。</em></p><p>实验一：去除RCAB块的CA layer。</p><p>实验方法：将RCAB块中的CAlayer去掉。其余网络结构与论文保持一致。训练500个epoch。</p><p>实验二：去除网络中的SSC和LSC。</p><p>实验方法：将网络中的SSC和LSC去掉。其余网络结构与论文保持一致。训练500个epoch。</p><p>实验三：利用反卷积进行上采样。</p><p>实验方法：用反卷积进行上采样。其余网络结构与论文保持一致。训练500个epoch。</p><p>​利用上述三个实验训练出来的网络，处理Set5数据集，分别求PSNR，SSIM，明度、饱和度的平均值，得到以下数据。数据有改动，上次是直接对三通道求PSNR，SSIM。这次是单独对Y通道计算（与论文方法一致）。</p><p><strong>实验一</strong></p><table><thead><tr class="header"><th></th><th><strong>HR</strong></th><th><strong>Base</strong></th><th><strong>No CA layer</strong></th><th><strong>No SSC LSC</strong></th><th><strong>Deconvolution</strong></th></tr></thead><tbody><tr class="odd"><td>PSNR</td><td>inf</td><td>13.884</td><td>13.902</td><td><strong>16.274</strong></td><td>15.822</td></tr><tr class="even"><td>SSIM</td><td>1</td><td>0.335</td><td>0.341</td><td><strong>0.378</strong></td><td>0.360</td></tr><tr class="odd"><td>明度</td><td>133.31</td><td>118.72</td><td><strong>123.49</strong></td><td>122.90</td><td>116.85</td></tr><tr class="even"><td>饱和度</td><td>125.88</td><td>43.24</td><td>49.41</td><td>58.96</td><td><strong>59.09</strong></td></tr></tbody></table><figure><img src="image-20230611152832760.png" alt="image-20230611152832760" /><figcaption aria-hidden="true">image-20230611152832760</figcaption></figure><p>​ 通过实验一(No CAlayer)与Base对比发现，去掉了通道注意力机制，对重建后的图像质量提升反而有一定的帮助，与论文中的实验结论相悖。另外去掉了通道注意力机制之后，同样进行500个epoch，训练时间大约缩短了20%。时间缩短的原因不难想出。去除了通道注意力机制之后，参数量减大大减少。参数量的减少带来了运算量的减少，所以训练时间与重建时间都会减少。</p><p>​ 效果变差的原因我认为是在进行计算通道表示符的时候，直接采用了globalpooling的方法将信息归一化至一个点，但是我认为特征图上的信息很大一部分靠位置来体现，这种全局池化的方式直接损失了位置信息。还有优化的空间。</p><p>​颜色的信息也有损失，但是我觉着不必担心，因为通过不断最小化L1Loss函数，更新网络的参数，会实现跟HR尽可能相近的颜色和结构信息。</p><p><strong>实验二</strong></p><figure><img src="image-20230611152915204.png" alt="image-20230611152915204" /><figcaption aria-hidden="true">image-20230611152915204</figcaption></figure><p>蓝色线是实验二的结果，绿色线是Base的结果。</p><p>​通过实验二与Base对比发现。在相同的迭代次数之下，实验二的loss值比base的高了大约11.3%。说明，SSC和LSC对加速训练有很大的影响。根据这个loss函数结果的不同，也能解释出实验三PSNR，SSIM更好的原因。因为训练效果不好，网络的主体权重还没怎么起作用，此时重建后图片的质量受上采样影响更大。另外通过对同一次训练不同时候取得的模型观测可以佐证这个结论。</p><figure><img src="image-20230611153000026.png" alt="image-20230611153000026" /><figcaption aria-hidden="true">image-20230611153000026</figcaption></figure><p>​此时训练的迭代次数较少，导致网络主体对图像影响不大，而图像产生较好的结果的原因是，上采样LR图像重建后的结果。</p><p><strong>实验三</strong></p><figure><img src="image-20230611153017387.png" alt="image-20230611153017387" /><figcaption aria-hidden="true">image-20230611153017387</figcaption></figure><p>​之所以做实验三，是因为我发现，重建后的图像会出现九宫格。起初我认为是dataloader有问题，修改之后问题仍然存在。后面发现随着迭代次数的增加，九宫格的线会渐渐变细。因此我认为是网络中的一部分出了问题。又因为这个线出现的位置很特殊，每次总是把图像等分，所以我认为是上采样环节出了问题，所以采用反卷积代替的。但是代替后仍出现了九宫格。</p><p><strong>补充实验</strong></p><p>​用十一张320*180的风景图像，五张较大的（长宽都超过1200像素）细节更多的建筑的图像，以及五张较大的颜色丰富的花朵图像，用BD方式下采样4倍，分别输入到上述得到的四个模型中，并求平均值，得到以下数据。</p><figure><img src="image-20230611153348034.png" alt="image-20230611153348034" /><figcaption aria-hidden="true">image-20230611153348034</figcaption></figure><p>​ 得到的数据跟上次的结果相近，大部分情况下都是实验二的效果最好</p><p>​通过Flower与其他两组数据对比，发现Flower的SSIM指标很高。SSIM指标反映的是重建图像与HR图像在亮度、对比度和结构三方面的相似程度。所以我的想法是，分别求出上述四种种数据集在不同网络的HR图像和SR图像的亮度对比函数、对比度对比函数、结构相关系数，求取平均值，经过对比就能发现RCAN网络的短板。从而想办法去加强。</p><p>根据SSIM指标的计算公式，分别对上述几个数据集求L（Luminance亮度）C（Contrast 对比度）S（Structure 结构）</p><figure><img src="image-20230611153554031.png" alt="image-20230611153554031" /><figcaption aria-hidden="true">image-20230611153554031</figcaption></figure><p>​经过数据集间相互对比发现，Flower的SSIM的指标更高的原因在于S复原的更好。另外在其他数据集中发现，L复原的效果最好，一般情况下S、C还有进步空间。</p><p>​ 下面是效果展示。（图像尺寸有修改）</p><p>​ 因为人类视觉局部性的特点所以实际求SSIM是，SSIM在实际实现中是利用的是一个窗口在整个图像上逐像素移动。局部求解SSIM然后再利用高斯加权函数避免分块效应，再求取平均值作为全局的SSIM。所以通过上述算出的L、S、C相乘得到的SSIM与表格中的SSIM有出入。但是上述的L、S、C也可以大致反映出网络在这三个层面的表现。</p><figure><img src="image-20230611153627432.png" alt="image-20230611153627432" /><figcaption aria-hidden="true">image-20230611153627432</figcaption></figure><figure><img src="image-20230611153654173.png" alt="image-20230611153654173" /><figcaption aria-hidden="true">image-20230611153654173</figcaption></figure><figure><img src="image-20230611153658316.png" alt="image-20230611153658316" /><figcaption aria-hidden="true">image-20230611153658316</figcaption></figure><figure><img src="image-20230611153702383.png" alt="image-20230611153702383" /><figcaption aria-hidden="true">image-20230611153702383</figcaption></figure><figure><img src="image-20230611153706621.png" alt="image-20230611153706621" /><figcaption aria-hidden="true">image-20230611153706621</figcaption></figure><figure><img src="image-20230611153712884.png" alt="image-20230611153712884" /><figcaption aria-hidden="true">image-20230611153712884</figcaption></figure><figure><img src="image-20230611153720505.png" alt="image-20230611153720505" /><figcaption aria-hidden="true">image-20230611153720505</figcaption></figure><figure><img src="image-20230611153724001.png" alt="image-20230611153724001" /><figcaption aria-hidden="true">image-20230611153724001</figcaption></figure><figure><img src="image-20230611153727546.png" alt="image-20230611153727546" /><figcaption aria-hidden="true">image-20230611153727546</figcaption></figure><figure><img src="image-20230611153731936.png" alt="image-20230611153731936" /><figcaption aria-hidden="true">image-20230611153731936</figcaption></figure><figure><img src="image-20230611153734640.png" alt="image-20230611153734640" /><figcaption aria-hidden="true">image-20230611153734640</figcaption></figure><figure><img src="image-20230611153738113.png" alt="image-20230611153738113" /><figcaption aria-hidden="true">image-20230611153738113</figcaption></figure><p>​通过Flower_LR与其他LR对比发现，前者图像更加简洁，后者的图像中有很多细节信息，我想这是导致SSIM指标不同的主要原因。</p><p>​另外重建出的Set5、landscape与重建出的Building、Flower对比发现，较大的图像重建出来九宫格现象就很浅，较小的图像的九宫格就比较明显。通过这点我认为九宫格的出现跟卷积核的大小与输入图像的尺寸的比例有关系。输入的尺寸较小时，卷积核的感受野占比就更大，提取特征时就会提取不到更多的细节特征，另外在重建时，卷积和尺寸也较大，也会忽略一部分细节信息。</p><h2 id="结论">结论</h2><p>​关于实验一的结果与论文相悖，我认为是训练迭代次数太少了（因为算力的问题，没有训练到模型收敛）。通过实验一，我认为这里的通道注意力机制像是锦上添花的部分，因为网络在收敛之前，重建的图像质量波动较大，所以在网络还没有收敛之前很难体现这里通道注意力的作用。所以才得出了与论文相悖的结论。另外在通道注意力机制中，全局平均池化操作仍有优化的可能。</p><p>​实验二，发现SSC和LSC在网络的训练中起着重要的作用，能以较大幅度加速训练过程。另外类似残差的结构能使网络扩展更多层而不出现梯度和消失梯度爆炸。</p><p>​实验三，最后还是留下了九宫格的问题，不过根据目前的趋势，我认为随着训练的进行可能会九宫格会消失。因为神经网络具有学习能力，通过调整参数会慢慢淡化九宫格。</p><p>​通过其他测试集的实验，发现网络在重建图像的对比度和结构还存在问题。另外就是九宫格的出现与输入图像的尺寸和卷积核的大小的比例有关。</p>]]></content>
    
    
    <categories>
      
      <category>论文精读</category>
      
    </categories>
    
    
    <tags>
      
      <tag>RCAN单幅图像超分辨率</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
